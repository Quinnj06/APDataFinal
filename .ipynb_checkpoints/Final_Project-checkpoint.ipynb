{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af3f71df-9dd4-4e13-b2b8-eb3d3055ca61",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Final Project - From Raw Data to Insights: A Full-Cycle Data Analytics Project\n",
    "This is an **group-optional** assignment. Total: **100 points**. Due:**<span style=\"color:red\"> Tuesday, December 16, 11:59 pm <span>**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02884308-5740-41f0-ae17-5c9aef8ee461",
   "metadata": {},
   "source": [
    "**Description**:\n",
    "This final project is designed to encapsulate the core skills you have acquired throughout the Applied Data Analytics course. You will embark on a journey from raw data acquisition to insightful visualizations and analysis. This project aims to reflect real-world data analytics workflows and challenges, providing you with a platform to showcase your proficiency in the tools and techniques covered in the course.\n",
    "\n",
    "**Proposal**:\n",
    "Submit a proposal outlining the dataset you intend to utilize for your project. Your proposal should include a description of the dataset, such as its source, structure, and key features, along with a brief explanation of why you chose this dataset and how it aligns with your objectives. Additionally, please provide a list of specific questions or problems you aim to address using this dataset. These questions should highlight the analytical goals or insights you hope to uncover and demonstrate how your work contributes to understanding or solving a broader issue. Due:**<span style=\"color:red\"> Sunday, November 23, 11:59 pm <span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87148e7a-644b-4552-9049-84f65dae707d",
   "metadata": {},
   "source": [
    "**Project Objectives**:\n",
    "\n",
    "**Problem Definition**: Clearly defining the question or problem that the analysis aims to address.\n",
    "\n",
    "**Data Acquisition**: \n",
    "* Utilize web scraping techniques to gather raw data from the internet. You may choose to scrape data from social media, e-commerce sites, public government data, or any other legal and ethical sources.\n",
    "* If web scraping does not apply to your chosen topic, you may instead use an existing dataset that already contains collected data but requires partial cleaning or preprocessing. This can include datasets with missing values, inconsistent formats, or fields that need transformation before analysis.\n",
    "* Ensure that the dataset you choose is rich enough to support meaningful exploration and insights, containing at least several hundred records and multiple fields of interest.\n",
    "\n",
    "**Data Cleaning with Pandas**:\n",
    "\n",
    "* Import the gathered data into a Jupyter Notebook.\n",
    "* Use the Pandas library to perform data cleansing which includes handling missing values, eliminating duplicates, correcting errors, and standardizing formats.\n",
    "* Transform the data as necessary to facilitate efficient storage and analysis. This may include pivoting, merging, or reshaping data.\n",
    "\n",
    "**Database Storage**:\n",
    "\n",
    "* Choose a suitable database (MySQL or MongoDB) for storing your cleansed dataset. Consider the nature of your data and the type of queries you will run when making your choice.\n",
    "* Create a schema for a SQL database or a suitable structure for a NoSQL database and populate it with your cleansed data.\n",
    "\n",
    "**Data Analysis in Jupyter Notebook**:\n",
    "\n",
    "* Conduct a **comprehensive** analysis of your dataset within a Jupyter notebook.\n",
    "* This should encompass descriptive statistical measures, an examination of correlations among different variables, and additional relevant analyses.\n",
    "\n",
    "**Visualization with Tableau**:\n",
    "\n",
    "* Create a series of visualizations that illustrate your findings using Tableau.\n",
    "* Your visualizations should include at least one dashboard summarizing the key insights from your data.\n",
    "* Employ best practices in data visualization to ensure that your visualizations are both informative and engaging.\n",
    "\n",
    "**Deliverables**:\n",
    "* On Gradescope:\n",
    "    * A **Jupyter Notebook** containing all code for web scraping, data cleansing, and analysis with detailed comments explaining each step of the process.\n",
    "    * A **report within the Jupyter notebook** that discusses your methods, findings, and the implications of the analysis.\n",
    "    * A **set of Tableau visualizations** including at least one dashboard, accompanied by a brief narrative explaining the story that each visualization tells about the data. This can either be incorporated into the Jupyter notebook or submitted independently as a Tableau workbook.\n",
    "    * **SQL/NoSQL scripts** used to create and populate the database or the **database** itself. <br>\n",
    "    * A short **5 min. video presentation** summarizing the project methodology, findings, and visualizations in a clear and concise manner."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
